{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q gradio sentence-transformers groq\n",
        "\n",
        "# Imports\n",
        "import gradio as gr\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# üîê Set your Groq API Key here\n",
        "os.environ['GROQ_API_KEY'] = \"YOUR_GROQ_API_KEY\"  # Replace this with your actual Groq key\n",
        "\n",
        "# Load sentence transformer\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Sample corpus for plagiarism detection\n",
        "corpus = [\n",
        "    \"Artificial intelligence is transforming the world.\",\n",
        "    \"Climate change is one of the greatest challenges.\",\n",
        "    \"The mitochondria is the powerhouse of the cell.\",\n",
        "    \"Quantum computing uses principles of quantum mechanics.\"\n",
        "]\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Plagiarism check\n",
        "def check_plagiarism(sentences):\n",
        "    results = []\n",
        "    for sent in sentences:\n",
        "        query_embedding = model.encode(sent, convert_to_tensor=True)\n",
        "        hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=1)\n",
        "        score = hits[0][0]['score']\n",
        "        if score > 0.75:\n",
        "            results.append((\"plagiarized\", sent))\n",
        "        else:\n",
        "            results.append((\"original\", sent))\n",
        "    return results\n",
        "\n",
        "# Detect AI using LLaMA 3 via Groq\n",
        "def detect_ai_sentences(text):\n",
        "    prompt = f\"\"\"You are an expert AI text detector. Return a list of sentence indexes (0-based) that are likely AI-generated in the given text:\\n\\n{text}\"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.environ['GROQ_API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"llama3-70b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.3\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data)\n",
        "    content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    try:\n",
        "        indexes = list(map(int, re.findall(r'\\d+', content)))\n",
        "    except:\n",
        "        indexes = []\n",
        "    return indexes\n",
        "\n",
        "# Humanize text using LLaMA 3\n",
        "def humanize_text(text):\n",
        "    prompt = f\"\"\"Rewrite the following text to sound more natural, human-like, and less AI-generated:\\n\\n{text}\"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {os.environ['GROQ_API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"llama3-70b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.groq.com/openai/v1/chat/completions\", headers=headers, json=data)\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Highlight AI and plagiarism\n",
        "def highlight_text(text, plagiarism_result, ai_indexes):\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    html = \"\"\n",
        "    for i, sent in enumerate(sentences):\n",
        "        styles = []\n",
        "        if plagiarism_result[i][0] == \"plagiarized\":\n",
        "            styles.append(\"background-color:#ffcccc\")  # red\n",
        "        if i in ai_indexes:\n",
        "            styles.append(\"background-color:#fff4cc\")  # yellow\n",
        "        if styles:\n",
        "            html += f\"<span style='{';'.join(styles)}'>{sent}</span> \"\n",
        "        else:\n",
        "            html += sent + \" \"\n",
        "    return html.strip()\n",
        "\n",
        "# Final logic\n",
        "def analyze_text(input_text):\n",
        "    words = input_text.split()\n",
        "    if len(words) > 1500:\n",
        "        return \"‚ö†Ô∏è Please limit your input to 1500 words.\", \"\", \"\", \"\"\n",
        "\n",
        "    sentences = re.split(r'(?<=[.!?]) +', input_text)\n",
        "\n",
        "    # Plagiarism check\n",
        "    plagiarism_result = check_plagiarism(sentences)\n",
        "    plagiarized_sentences = [s for tag, s in plagiarism_result if tag == \"plagiarized\"]\n",
        "\n",
        "    # AI detection\n",
        "    ai_indexes = detect_ai_sentences(input_text)\n",
        "\n",
        "    # Highlight output\n",
        "    html_result = highlight_text(input_text, plagiarism_result, ai_indexes)\n",
        "\n",
        "    # Percentages\n",
        "    total = len(sentences)\n",
        "    ai_percent = (len(ai_indexes) / total) * 100 if total > 0 else 0\n",
        "    plagiarism_percent = (len(plagiarized_sentences) / total) * 100 if total > 0 else 0\n",
        "\n",
        "    # Humanized text\n",
        "    humanized = humanize_text(input_text)\n",
        "\n",
        "    return (\n",
        "        html_result,\n",
        "        f\"{ai_percent:.2f}%\",\n",
        "        f\"{plagiarism_percent:.2f}%\",\n",
        "        humanized\n",
        "    )\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üîç AI & Plagiarism Detector + Humanizer\")\n",
        "    gr.Markdown(\"\"\"\n",
        "- üî¥ Red = Plagiarized text\n",
        "- üü° Yellow = AI-generated text\n",
        "- Get AI % and Plagiarism %\n",
        "- Bonus: Humanized rewrite of your text\n",
        "\"\"\")\n",
        "\n",
        "    text_input = gr.Textbox(label=\"Input Text (max 1500 words)\", lines=15, placeholder=\"Paste your content here...\")\n",
        "\n",
        "    analyze_button = gr.Button(\"Analyze\")\n",
        "\n",
        "    html_output = gr.HTML()\n",
        "    ai_percent_output = gr.Textbox(label=\"AI-Generated Percentage\", interactive=False)\n",
        "    plagiarism_percent_output = gr.Textbox(label=\"Plagiarism Percentage\", interactive=False)\n",
        "    humanized_output = gr.Textbox(label=\"Humanized Text\", lines=10)\n",
        "\n",
        "    analyze_button.click(\n",
        "        analyze_text,\n",
        "        inputs=text_input,\n",
        "        outputs=[\n",
        "            html_output,\n",
        "            ai_percent_output,\n",
        "            plagiarism_percent_output,\n",
        "            humanized_output\n",
        "        ]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "ogJa4D3fj_9i",
        "outputId": "a89c9a66-00e1-44fc-94a3-f0f3fae7f83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://36c4c8fb6c743116ef.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://36c4c8fb6c743116ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}