{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiTdcGy0Z-ae",
        "outputId": "974c1f1a-9cf1-41ad-cd69-1ac4fc5c1104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 📦 Install dependencies\n",
        "!pip install -q groq langchain langchain-community faiss-cpu gradio tiktoken transformers sentence-transformers\n",
        "!pip install -q pillow requests\n"
      ]
    },
    {
      "source": [
        "# 📦 Install dependencies\n",
        "!pip install -q groq langchain langchain-community faiss-cpu gradio tiktoken transformers sentence-transformers langchain-groq\n",
        "!pip install -q pillow requests\n",
        "\n",
        "# 🔐 API Keys\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# 📚 LangChain & Others\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import gradio as gr"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dzUBS_p1al2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📄 Prompt Template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"title\"],\n",
        "    template=\"\"\"\n",
        "You are a blog writing assistant. Write a detailed, engaging blog post of ~300 words on the topic: \"{title}\". Make it informative, SEO-friendly, and interesting.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 🤖 Initialize LLM via GROQ\n",
        "llm = ChatGroq(temperature=0.7, model_name=\"llama3-8b-8192\")\n",
        "\n",
        "# 🔁 Blog Writing Chain\n",
        "blog_chain = LLMChain(llm=llm, prompt=prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhOf_kiCayQR",
        "outputId": "0638d0e1-9dd6-4f77-d7ac-5932804d4ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4027785766>:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  blog_chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(title):\n",
        "    prompt = f\"High-quality image illustrating: {title}\"\n",
        "    # Replace with your own API request (e.g., replicate or stability)\n",
        "    url = \"https://image.pollinations.ai/prompt/\" + title.replace(\" \", \"%20\")\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "IvVOXm8ca3Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_link(title):\n",
        "    search_query = title.replace(\" \", \"+\")\n",
        "    youtube_search_url = f\"https://www.youtube.com/results?search_query={search_query}+AI+generated+video\"\n",
        "    return youtube_search_url\n"
      ],
      "metadata": {
        "id": "FJ5vX25ieb-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blog_bot(title):\n",
        "    blog = blog_chain.run(title)\n",
        "    image = generate_image(title)\n",
        "    video_link = generate_video_link(title)\n",
        "    return blog, image, video_link\n"
      ],
      "metadata": {
        "id": "5HU5orzfecBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 📝 Blog Generator with GROQ + Image + YouTube Video Link\")\n",
        "\n",
        "    title = gr.Textbox(label=\"Enter Blog Title\")\n",
        "    generate = gr.Button(\"Generate Blog\")\n",
        "\n",
        "    blog_output = gr.Textbox(label=\"Generated Blog\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "    video_output = gr.Textbox(label=\"YouTube Search Link\")\n",
        "\n",
        "    def full_pipeline(title):\n",
        "        blog = blog_chain.run(title)\n",
        "        image = generate_image(title)\n",
        "        video_link = generate_video_link(title)\n",
        "        return blog, image, video_link\n",
        "\n",
        "    generate.click(fn=full_pipeline, inputs=title, outputs=[blog_output, image_output, video_output])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "GKCocitqecD9",
        "outputId": "f7e894e0-53aa-488e-a139-62fda85313b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1351dd390c4de66a07.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1351dd390c4de66a07.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Install dependencies\n",
        "!pip install -q groq langchain langchain-community faiss-cpu gradio tiktoken transformers sentence-transformers langchain-groq wikipedia\n",
        "!pip install -q pillow requests fpdf gTTS\n",
        "\n",
        "# 🔐 API Keys\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# 📚 Imports\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import gradio as gr\n",
        "from fpdf import FPDF\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "\n",
        "# 📄 Prompt Templates\n",
        "blog_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\"],\n",
        "    template=\"\"\"\n",
        "You are a blog writing assistant. Write a detailed, engaging blog post of ~300 words on the topic: \"{title}\". Make it informative, SEO-friendly, and interesting.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "seo_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\"],\n",
        "    template=\"\"\"\n",
        "Generate the following for the blog titled \"{title}\":\n",
        "1. Meta Title\n",
        "2. Meta Description\n",
        "3. 5 SEO Keywords\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 🧠 Initialize LLM\n",
        "llm = ChatGroq(temperature=0.7, model_name=\"llama3-8b-8192\")\n",
        "blog_chain = LLMChain(llm=llm, prompt=blog_prompt)\n",
        "seo_chain = LLMChain(llm=llm, prompt=seo_prompt)\n",
        "\n",
        "# 🌐 Wikipedia Fact Checker\n",
        "retriever = WikipediaRetriever()\n",
        "fact_checker = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "# 🖼️ Image Generator\n",
        "styles = [\"realistic\", \"cartoon\", \"abstract\"]\n",
        "def generate_image(title, style):\n",
        "    prompt = f\"{style} style: {title}\"\n",
        "    url = \"https://image.pollinations.ai/prompt/\" + prompt.replace(\" \", \"%20\")\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))\n",
        "\n",
        "# 🎧 Text-to-Speech\n",
        "def blog_to_speech(text):\n",
        "    tts = gTTS(text)\n",
        "    temp_audio = tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False)\n",
        "    tts.save(temp_audio.name)\n",
        "    return temp_audio.name\n",
        "\n",
        "# 📄 PDF Export\n",
        "def export_to_pdf(title, blog):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, f\"Title: {title}\\n\\n{blog}\")\n",
        "    temp_pdf = tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False)\n",
        "    pdf.output(temp_pdf.name)\n",
        "    return temp_pdf.name\n",
        "\n",
        "# 🎮 YouTube Search\n",
        "def generate_video_link(title):\n",
        "    search_query = title.replace(\" \", \"+\")\n",
        "    return f\"https://www.youtube.com/results?search_query={search_query}+AI+generated+video\"\n",
        "\n",
        "# 🔁 Main Blog Generator\n",
        "def blog_bot(title, style):\n",
        "    blog = blog_chain.run(title)\n",
        "    seo = seo_chain.run(title)\n",
        "    facts = fact_checker.run(title)\n",
        "    image = generate_image(title, style)\n",
        "    video_link = generate_video_link(title)\n",
        "    pdf_path = export_to_pdf(title, blog)\n",
        "    audio_path = blog_to_speech(blog)\n",
        "    return blog, image, video_link, seo, facts, pdf_path, audio_path\n",
        "\n",
        "# 🏐️ Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 📝 Blog Generator with GROQ + Multi-Modal AI\")\n",
        "\n",
        "    with gr.Row():\n",
        "        title = gr.Textbox(label=\"Enter Blog Title\")\n",
        "        style = gr.Dropdown(choices=styles, label=\"Image Style\", value=\"realistic\")\n",
        "\n",
        "    generate = gr.Button(\"Generate Blog\")\n",
        "\n",
        "    blog_output = gr.Textbox(label=\"Generated Blog\")\n",
        "    seo_output = gr.Textbox(label=\"SEO Suggestions\")\n",
        "    facts_output = gr.Textbox(label=\"Wikipedia Fact Check\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "    video_output = gr.Textbox(label=\"YouTube Video Link\")\n",
        "    pdf_output = gr.File(label=\"Download Blog as PDF\")\n",
        "    audio_output = gr.Audio(label=\"Listen to Blog\")\n",
        "\n",
        "    generate.click(\n",
        "        fn=blog_bot,\n",
        "        inputs=[title, style],\n",
        "        outputs=[blog_output, image_output, video_output, seo_output, facts_output, pdf_output, audio_output]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "nFiCkqI9ecGe",
        "outputId": "6e744712-1041-4e0f-a07b-ffb3f0f46042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9fcf496a7549313f62.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fcf496a7549313f62.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5a7ok72pecIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}